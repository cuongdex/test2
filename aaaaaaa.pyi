# -*- coding: utf-8 -*-
"""aaaaaaa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XVKkvr-5_VWOvZUAao509EZ6vYwZP_or
"""

!pip install torch torchvision diffusers transformers

import torch
from torch import nn
from torch.optim import Adam
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
from diffusers import UNet2DModel, DDPMScheduler
import os

# Đường dẫn đến dataset trên local
data_dir = "/content/drive/MyDrive/PetImages"

# Chuyển đổi và chuẩn hóa ảnh
transform = transforms.Compose([
    transforms.Resize(64),            # Thay đổi kích thước ảnh về 64x64
    transforms.CenterCrop(64),        # Cắt giữa ảnh để đảm bảo đúng kích thước
    transforms.ToTensor(),            # Chuyển đổi ảnh thành tensor
    transforms.Normalize([0.5], [0.5]) # Chuẩn hóa ảnh về khoảng [-1, 1]
])

# Tạo dataset từ local
train_dataset = datasets.ImageFolder(root=os.path.join(data_dir), transform=transform)

# Tạo DataLoader
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)


# Các bước tiếp theo sử dụng train_loader như đã mô tả trước đây
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Tạo mô hình U-Net
model = UNet2DModel(
    sample_size=64,           # Kích thước ảnh
    in_channels=3,            # Số kênh đầu vào (3 cho RGB)
    out_channels=3,           # Số kênh đầu ra
    layers_per_block=2,       # Số lớp trong mỗi block
    block_out_channels=(64, 128, 256, 512), # Số kênh cho mỗi block
    down_block_types=("DownBlock2D", "DownBlock2D", "DownBlock2D", "AttnDownBlock2D"),
    up_block_types=("UpBlock2D", "UpBlock2D", "UpBlock2D", "AttnUpBlock2D"),
).to(device)

# Lịch trình nhiễu DDPM
noise_scheduler = DDPMScheduler(num_train_timesteps=1000)

# Cấu hình bộ tối ưu hóa
optimizer = Adam(model.parameters(), lr=1e-4)

# Hàm huấn luyện (như trong mã trước)
def train_model(model, train_loader, noise_scheduler, optimizer, num_epochs=10):
    model.train()

    for epoch in range(num_epochs):
        for step, (images, _) in enumerate(train_loader):
            images = images.to(device)
            noise = torch.randn_like(images).to(device) # Tạo nhiễu ngẫu nhiên

            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (images.shape[0],), device=device).long()
            noisy_images = noise_scheduler.add_noise(images, noise, timesteps)

            optimizer.zero_grad()
            pred_noise = model(noisy_images, timesteps).sample
            loss = nn.MSELoss()(pred_noise, noise) # MSE giữa nhiễu dự đoán và nhiễu thực

            loss.backward()
            optimizer.step()

            if step % 100 == 0:
                print(f"Epoch {epoch+1}, Step {step}, Loss: {loss.item():.4f}")

# Huấn luyện mô hình
train_model(model, train_loader, noise_scheduler, optimizer, num_epochs=5)

import matplotlib.pyplot as plt

def generate_image(model, noise_scheduler):
    model.eval()
    with torch.no_grad():
        noise = torch.randn((1, 3, 64, 64)).to(device)
        for t in reversed(range(noise_scheduler.num_train_timesteps)):
            timesteps = torch.full((1,), t, device=device, dtype=torch.long)
            noise_pred = model(noise, timesteps).sample
            noise = noise_scheduler.step(noise_pred, timesteps, noise).prev_sample

        # Chuyển đổi tensor thành ảnh để hiển thị
        image = noise.squeeze().cpu().permute(1, 2, 0).numpy()
        image = (image * 127.5 + 127.5).clip(0, 255).astype("uint8")

        # Hiển thị hình ảnh
        plt.imshow(image)
        plt.axis('off')  # Ẩn trục
        plt.show()

generate_image(model, noise_scheduler)